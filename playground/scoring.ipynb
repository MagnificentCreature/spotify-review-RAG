{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ee5700f1574c9a86e999e32e15b4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc31693e8f5442ea1ff161af142642f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c4a021175d4202bf5e17ea5c685cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69cf11fdd484d8d819c46e9eae6c905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc282bd9e4a2473da5708d25f7733300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85ebdabc574432fa72346dae6c7383a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.9666109085083008, 'Recall': 0.9666109085083008, 'F1': 0.9666109085083008}\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "def evaluate_bertscore(generated_text, reference_text):\n",
    "    P, R, F1 = score([generated_text], [reference_text], lang=\"en\")\n",
    "    return {\"Precision\": P.item(), \"Recall\": R.item(), \"F1\": F1.item()}\n",
    "\n",
    "# Example texts\n",
    "gen_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "ref_text = \"A fast brown fox leaps over a sleepy canine.\"\n",
    "\n",
    "# Compute semantic similarity\n",
    "print(evaluate_bertscore(gen_text, ref_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.9229757189750671, 'Recall': 0.9435864090919495, 'F1': 0.9331672787666321}\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "gen_text = \"This app is amazing and works smoothly.\"\n",
    "ref_text = \"Amazing app with smooth performance.\"\n",
    "print(evaluate_bertscore(gen_text, ref_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1666666618055557\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "def evaluate_rouge(generated_text, reference_text):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(generated_text, reference_text)\n",
    "    return scores[0]  # ROUGE-1, ROUGE-2, ROUGE-L scores\n",
    "\n",
    "# Example\n",
    "gen_text = \"This app is amazing and works smoothly.\"\n",
    "ref_text = \"Amazing app with smooth performance.\"\n",
    "\n",
    "result = evaluate_rouge(gen_text, ref_text)\n",
    "\n",
    "print(f\"Score: {result[\"rouge-l\"]['f']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
