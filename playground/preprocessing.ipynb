{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# from llama_index import (Document)\n",
    "\n",
    "# Load documents from the review dataset directory (adjust path as needed)\n",
    "csv_path = \"../data/SPOTIFY_REVIEWS_DEDUP.csv\"\n",
    "df = pd.read_csv(csv_path, usecols=[\"review_text\",\"review_rating\",\"review_likes\"], nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# from llama_index import (Document)\n",
    "\n",
    "# Load documents from the review dataset directory (adjust path as needed)\n",
    "csv_path = \"../Data/SPOTIFY_REVIEWS.csv\"\n",
    "df = pd.read_csv(csv_path, usecols=[\"review_text\",\"review_rating\",\"review_likes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with review text less than 5 tokens\n",
    "def remove_short_lines(df, length=4):\n",
    "    return df.loc[df[\"review_text\"].str.count(\" \") >= length]\n",
    "\n",
    "def preprocess_text(df):\n",
    "    df.drop_duplicates(subset=[\"review_text\"], inplace=True)\n",
    "    df.dropna(subset=[\"review_text\"], inplace=True)\n",
    "    df[\"review_text\"] = (\n",
    "        df[\"review_text\"]\n",
    "        .str.replace(r'\\W+', ' ', regex=True)  # replace non-alphanumeric with space\n",
    "        .str.replace(r'\\s+', ' ', regex=True)  # collapse whitespace\n",
    "        .str.lower()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df = remove_short_lines(df)\n",
    "df = preprocess_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Load SymSpell dictionary (ensure you have \"frequency_dictionary_en.txt\")\n",
    "dictionary_path = importlib.resources.files(\"symspellpy\") / \"frequency_dictionary_en_82_765.txt\"\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2)\n",
    "sym_spell.load_dictionary(str(dictionary_path), term_index=0, count_index=1)\n",
    "\n",
    "def correct_spelling(text):\n",
    "    words = text.split()  # Split the sentence into words\n",
    "    corrected_words = [sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2)[0].term if sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2) else word for word in words]\n",
    "    return ' '.join(corrected_words)  # Reassemble the sentence\n",
    "\n",
    "def correct_spelling_parallel_joblib(df):\n",
    "    corrected_reviews = Parallel(n_jobs=-1)(delayed(correct_spelling)(text) for text in df['review_text'])\n",
    "    df['review_text'] = corrected_reviews\n",
    "    return df\n",
    "\n",
    "# Apply to DataFrame\n",
    "df = correct_spelling_parallel_joblib(df)\n",
    "\n",
    "\n",
    "# df[\"review_text\"] = df[\"review_text\"].apply(lambda x: correct_spelling(x))\n",
    "# df[\"review_text\"] = correct_spelling_parallel(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(df):\n",
    "    df['review_text'] = df['review_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "remove_stopwords(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_short_lines(df, length=4)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "from cuml.feature_extraction.text import TfidfVectorizer as cuTfidfVectorizer\n",
    "from cuml.metrics.pairwise_distances import pairwise_distances\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cupy as cp  # GPU-accelerated NumPy\n",
    "import cupyx.scipy.sparse as cpx  # Sparse CuPy operations\n",
    "from cuml.neighbors import NearestNeighbors  # RAPIDS GPU-optimized ANN\n",
    "\n",
    "def vectorized_deduplicate_dataframe(df, text_column=\"review_text\", threshold=0.8):\n",
    "    \"\"\"\n",
    "    Efficiently deduplicates a dataframe based on text similarity using TF-IDF and cosine similarity on GPU using RAPIDS cuML.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): Input DataFrame containing text data.\n",
    "    - text_column (str): Column name of text data.\n",
    "    - threshold (float): Similarity threshold (0 to 1), where higher means stricter deduplication.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Deduplicated DataFrame with all original columns preserved.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute TF-IDF embeddings on GPU\n",
    "    vectorizer = cuTfidfVectorizer(stop_words=\"english\")\n",
    "    tfidf_matrix = vectorizer.fit_transform(df[text_column])  # Sparse matrix\n",
    "\n",
    "    print(\"Fitted and normalised matrix\")\n",
    "\n",
    "    # tfidf_matrix_gpu = cp.asarray(tfidf_matrix.toarray())  # Move data to GPU\n",
    "\n",
    "    # # Compute cosine similarity matrix on GPU\n",
    "    # similarity_matrix_gpu = pairwise_distances(tfidf_matrix_gpu, tfidf_matrix_gpu, metric=\"cosine\")\n",
    "    # print(\"Computed similarity matrix on GPU\")\n",
    "\n",
    "    # Convert to sparse CuPy matrix (Keep it sparse!)\n",
    "    tfidf_matrix_gpu = cpx.csr_matrix(tfidf_matrix)  \n",
    "\n",
    "    # Use RAPIDS NearestNeighbors (FAISS alternative)\n",
    "    nn = NearestNeighbors(n_neighbors=5, metric=\"cosine\", algorithm=\"brute\", output_type=\"numpy\")\n",
    "    nn.fit(tfidf_matrix_gpu)\n",
    "\n",
    "    print(\"Computed Nearest Neighbors on GPU\")\n",
    "\n",
    "    # Identify duplicates\n",
    "    unique_indexes = []\n",
    "    seen = set()\n",
    "\n",
    "    distances, indices = nn.kneighbors(tfidf_matrix_gpu, n_neighbors=5)\n",
    "\n",
    "\n",
    "    for i in tqdm(range(len(df))):\n",
    "        if i in seen:\n",
    "            continue\n",
    "        # Find similar reviews\n",
    "        # similar_indexes = pairwise_distances(similarity_matrix_gpu[i], similarity_matrix_gpu[i], metric=\"cosine\").toarray()\n",
    "        # similar_indexes = [idx for idx, val in enumerate(similar_indexes) if val > threshold]\n",
    "\n",
    "        similar_indexes = indices[i][distances[i] < threshold]        \n",
    "        seen.update(similar_indexes)  # Mark them as seen\n",
    "        unique_indexes.append(i)  # Keep only the first occurrence\n",
    "\n",
    "    # Return deduplicated DataFrame\n",
    "    return df.iloc[unique_indexes].reset_index(drop=True)\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df_dedup1 = vectorized_deduplicate_dataframe(df)\n",
    "\n",
    "print(df_dedup1.shape)\n",
    "print(df.shape)\n",
    "\n",
    "df = df_dedup1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "data = {\n",
    "    \"review_text\": [\n",
    "        \"This product is amazing!\",  # Original\n",
    "        \"This product is really amazing!\",  # Slight variation\n",
    "        \"Worst product ever.\",  # Different\n",
    "        \"Absolutely terrible, do not buy.\",  # Different\n",
    "        \"Amazing product! Really good.\",  # Similar to first\n",
    "        \"I love this item, it's fantastic!\",  # Different\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_test = pd.DataFrame(data)\n",
    "\n",
    "# Run the deduplication function\n",
    "df_dedup = vectorized_deduplicate_dataframe(df_test, threshold=0.8)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nOriginal DataFrame:\")\n",
    "print(df_test)\n",
    "\n",
    "print(\"\\nDeduplicated DataFrame:\")\n",
    "print(df_dedup)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "df = df.dropna(subset=[\"review_text\"])  # or df[\"review_text\"].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# save this as a new csv\n",
    "df.to_csv(\"../Data/SPOTIFY_REVIEWS_DEDUP.csv\", index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#show 30 lines with length 5\n",
    "df[df[\"review_text\"].str.count(\" \") == 4].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mini = df.sample(n=100000)\n",
    "\n",
    "df_mini['num_tokens'] =  df_mini['review_text'].apply(lambda text: 0 if not isinstance(text, str) else len(TextBlob(text).words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_mini['num_tokens'], kde=True, bins=50, color='blue')\n",
    "plt.xlabel('Number of tokens per review')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_likes</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3131012</th>\n",
       "      <td>I hate this app</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151445</th>\n",
       "      <td>Awesome and relaxing too</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687194</th>\n",
       "      <td>Great and simple to use.</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350308</th>\n",
       "      <td>Love it!</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303162</th>\n",
       "      <td>Love It</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292450</th>\n",
       "      <td>I LOVE THIS SO MUCHHH</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151996</th>\n",
       "      <td>Boycott this app</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700573</th>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040942</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549281</th>\n",
       "      <td>Nice</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748050</th>\n",
       "      <td>Could use some adjustments.</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637283</th>\n",
       "      <td>🙂</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199895</th>\n",
       "      <td>Awesome</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148502</th>\n",
       "      <td>Very bad app</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457505</th>\n",
       "      <td>nice app</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141960</th>\n",
       "      <td>👌👌👌👌👌</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828677</th>\n",
       "      <td>BAD!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984849</th>\n",
       "      <td>Awesome flexibility!</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203039</th>\n",
       "      <td>Useless</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452132</th>\n",
       "      <td>I love turtles</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         review_text  review_rating  review_likes  num_tokens\n",
       "3131012              I hate this app              1             0           4\n",
       "3151445     Awesome and relaxing too              5             0           4\n",
       "687194      Great and simple to use.              5             0           5\n",
       "2350308                     Love it!              5             0           2\n",
       "1303162                      Love It              5             0           2\n",
       "1292450        I LOVE THIS SO MUCHHH              5             0           5\n",
       "3151996             Boycott this app              1             0           3\n",
       "1700573                         Good              5             0           1\n",
       "1040942            Worth every penny              5             0           3\n",
       "2549281                         Nice              5             0           1\n",
       "748050   Could use some adjustments.              5             0           4\n",
       "1637283                            🙂              5             0           1\n",
       "1199895                      Awesome              5             0           1\n",
       "3148502                 Very bad app              1             0           3\n",
       "1457505                     nice app              5             0           2\n",
       "1141960                        👌👌👌👌👌              5             0           1\n",
       "2828677                      BAD!!!!              1             0           1\n",
       "984849          Awesome flexibility!              5             0           2\n",
       "1203039                      Useless              1             0           1\n",
       "1452132               I love turtles              5             0           3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_short_lines(df, length=5):\n",
    "    return df.loc[df['review_text'].str.count(\" \") < length]\n",
    "\n",
    "remove_short_lines(df_mini).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      7\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTextBlob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     13\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m], kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[15], line 10\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      7\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m text: \u001b[38;5;28mlen\u001b[39m(\u001b[43mTextBlob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m))\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     13\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m], kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\textblob\\decorators.py:23\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m---> 23\u001b[0m value \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\textblob\\blob.py:625\u001b[0m, in \u001b[0;36mTextBlob.words\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    619\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of word tokens. This excludes punctuation characters.\u001b[39;00m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;124;03m    If you want to include punctuation characters, access the ``tokens``\u001b[39;00m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;124;03m    property.\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \n\u001b[0;32m    623\u001b[0m \u001b[38;5;124;03m    :returns: A :class:`WordList <WordList>` of word tokens.\u001b[39;00m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWordList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_punc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\textblob\\blob.py:205\u001b[0m, in \u001b[0;36mWordList.__init__\u001b[1;34m(self, collection)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, collection):\n\u001b[0;32m    202\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize a WordList. Takes a collection of strings as\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m    its only argument.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m([Word(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m collection])\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\textblob\\tokenizers.py:76\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, include_punc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     70\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convenience function for tokenizing text into words.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m    NOTE: NLTK's word tokenizer expects sentences as input, so the text will be\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    tokenized to sentences before being tokenized to words.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     words \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m---> 76\u001b[0m         \u001b[43m_word_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_punc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sent_tokenize(text)\n\u001b[0;32m     78\u001b[0m     )\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m words\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\textblob\\base.py:68\u001b[0m, in \u001b[0;36mBaseTokenizer.itokenize\u001b[1;34m(self, text, *args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mitokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a generator that generates tokens \"on-demand\".\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.6.0\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    :rtype: generator\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\textblob\\tokenizers.py:34\u001b[0m, in \u001b[0;36mWordTokenizer.tokenize\u001b[1;34m(self, text, include_punc)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, include_punc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of word tokens.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    :param text: string of text.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    :param include_punc: (optional) whether to\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m        include punctuation as separate tokens. Default to True.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m include_punc:\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:144\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m:type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 144\u001b[0m     token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_treebank_word_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\destructive.py:182\u001b[0m, in \u001b[0;36mNLTKWordTokenizer.tokenize\u001b[1;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[0;32m    179\u001b[0m     text \u001b[38;5;241m=\u001b[39m regexp\u001b[38;5;241m.\u001b[39msub(substitution, text)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m regexp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCONTRACTIONS2:\n\u001b[1;32m--> 182\u001b[0m     text \u001b[38;5;241m=\u001b[39m regexp\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2 \u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m regexp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCONTRACTIONS3:\n\u001b[0;32m    184\u001b[0m     text \u001b[38;5;241m=\u001b[39m regexp\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2 \u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "from textblob import TextBlob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "df['num_tokens'] = df['review_text'].apply(lambda text: 0 if not isinstance(text, str) else len(TextBlob(text).words))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['num_tokens'], kde=True, bins=50, color='blue')\n",
    "plt.xlabel('Number of tokens per review')\n",
    "plt.ylabel('Frequency')\n",
    "df.drop(columns=['num_tokens'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([0], dtype='int32')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_mini\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1153\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1180\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteger\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1177\u001b[0m     \u001b[38;5;66;03m# We need to decide whether to treat this as a positional indexer\u001b[39;00m\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;66;03m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_should_fallback_to_positional:\n\u001b[1;32m-> 1180\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1182\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1183\u001b[0m             \u001b[38;5;66;03m# GH#50617\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.__getitem__ treating keys as positions is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1189\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1190\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1420\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1360\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1360\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1362\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\seanw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([0], dtype='int32')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "df_mini[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the reviews are quite short, we do not need to split them using text splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# module_name = \"faiss\"\n",
    "# if module_name in sys.modules:\n",
    "#     del sys.modules[module_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import faiss\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "models = {\n",
    "    'all-MiniLM-L6-v2': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    'multi-qa-MiniLM-L6-dot-v1': 'sentence-transformers/multi-qa-MiniLM-L6-dot-v1',\n",
    "    'paraphrase-MiniLM-L6-v2': 'sentence-transformers/paraphrase-MiniLM-L6-v2',\n",
    "}\n",
    "\n",
    "def select_model(m_key):\n",
    "    if m_key not in models:\n",
    "        raise ValueError(f'Model key is not found')\n",
    "    return SentenceTransformer(m_key, device=device)\n",
    "\n",
    "# import faiss\n",
    "# import torch\n",
    "\n",
    "# # Assume you have an index (e.g. a flat index on CPU)\n",
    "# cpu_index = faiss.IndexFlatL2(128)\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"Using FAISS GPU\")\n",
    "#     # Create GPU resources and transfer the index to GPU 0\n",
    "#     res = faiss.StandardGpuResources()\n",
    "#     gpu_index = faiss.index_cpu_to_gpu(res, 0, cpu_index)\n",
    "#     index = gpu_index\n",
    "# else:\n",
    "#     print(\"Using FAISS CPU\")\n",
    "#     index = cpu_index\n",
    "\n",
    "# # Now use `index` for your similarity search\n",
    "\n",
    "# def encode_in_batches(texts, embedding_model, batch_size=512):\n",
    "#     sample_emb = embedding_model.encode([df.iloc[0]['review_text']], device=device)\n",
    "#     emb_dim = len(sample_emb[0])\n",
    "\n",
    "#     index = faiss.IndexFlatL2(emb_dim)\n",
    "\n",
    "#     for i in tqdm(range(0, len(texts), batch_size), desc=\"Encoding batches\"):\n",
    "#         batch_texts = texts[i:i + batch_size]\n",
    "#         emb = embedding_model.encode(batch_texts, device=device)\n",
    "#         index.add(emb)\n",
    "\n",
    "#     print(\"Compressing index\")\n",
    "#     m = 64  # Number of sub-vectors\n",
    "#     clusters = 100  # Number of clusters\n",
    "#     index = faiss.IndexIVFPQ(index, emb_dim, clusters, m, 8)  # IVF with PQ (100 clusters, 8-bit codes)\n",
    "\n",
    "#     return index\n",
    "\n",
    "def encode_in_batches(texts, embedding_model, batch_size=512):\n",
    "    # Get embedding dimension\n",
    "    sample_emb = embedding_model.encode([texts[0]], device=device)\n",
    "    emb_dim = sample_emb.shape[1] if len(sample_emb.shape) > 1 else sample_emb.shape[0]\n",
    "\n",
    "    num_vectors = len(texts)\n",
    "    \n",
    "    # Dynamically adjust number of clusters\n",
    "    clusters = min(256, max(10, num_vectors // 40))  \n",
    "\n",
    "    if num_vectors < 9984:\n",
    "        print(f\"Dataset has only {num_vectors} vectors. Using IndexFlatL2 instead.\")\n",
    "        index = faiss.IndexFlatL2(emb_dim)  # Flat index (no training needed)\n",
    "    else:\n",
    "        print(f\"Using {clusters} clusters for IVF-PQ.\")\n",
    "\n",
    "        quantizer = faiss.IndexFlatL2(emb_dim)\n",
    "        index = faiss.IndexIVFPQ(quantizer, emb_dim, clusters, 64, 8)\n",
    "\n",
    "        # Collect training data\n",
    "        training_data = []\n",
    "        for i in tqdm(range(0, num_vectors, batch_size), desc=\"Encoding batches (Training)\"):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            emb = embedding_model.encode(batch_texts, device=device).astype(np.float32)\n",
    "            training_data.append(emb)\n",
    "            if len(training_data) * batch_size >= clusters * 40:\n",
    "                break\n",
    "\n",
    "        training_data = np.vstack(training_data)\n",
    "        print(f\"Training IVF-PQ with {training_data.shape[0]} vectors...\")\n",
    "        index.train(training_data)\n",
    "\n",
    "    # Add vectors\n",
    "    for i in tqdm(range(0, num_vectors, batch_size), desc=\"Encoding batches (Indexing)\"):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        emb = embedding_model.encode(batch_texts, device=device).astype(np.float32)\n",
    "        index.add(emb)\n",
    "\n",
    "    print(\"Index built successfully!\")\n",
    "    return index\n",
    "\n",
    "def gen_emb_store(df, m_key, cache_dir = './cache'):\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir)\n",
    "\n",
    "    # cache_file = os.path.join(cache_dir, f'{m_key}-embeddings.pickle')\n",
    "    cache_file = os.path.join(cache_dir, f\"{m_key}-index.idx\")\n",
    "\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f'Loading embedding from cache: {cache_file}')\n",
    "        # with open(cache_file, 'rb') as f:\n",
    "        #     vector_store = pickle.load(f)\n",
    "        # embed_model = select_model(m_key)\n",
    "\n",
    "        #load the faiss index\n",
    "        vector_store = faiss.read_index(f\"{cache_dir}/{m_key}-index.idx\")\n",
    "        embed_model = select_model(m_key)\n",
    "\n",
    "    else:\n",
    "        print(f'Generating embeddings for model: {m_key}')\n",
    "        embed_model = select_model(m_key)\n",
    "        texts = df['review_text'].tolist()\n",
    "        vector_store = encode_in_batches(texts, embed_model)\n",
    "\n",
    "        faiss.write_index(vector_store, f\"{cache_dir}/{m_key}-index.idx\")\n",
    "\n",
    "    return vector_store, embed_model\n",
    "\n",
    "def compare_models(df, model_keys, cache_dir='./cache'):\n",
    "    results = {}\n",
    "    for m_key in model_keys:\n",
    "        print(f'Processing model: {m_key}')\n",
    "        vector_store, embedder = gen_emb_store(df, m_key, cache_dir)\n",
    "        if vector_store is None:\n",
    "            raise ValueError(f\"Vector store creation failure for {m_key}\")\n",
    "\n",
    "        results[m_key] = (vector_store, embedder)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from tqdm import tqdm\n",
    "\n",
    "def documents_from_df(df, text_field=\"review_text\", batch_size=256):\n",
    "    \"\"\"\n",
    "    Convert a DataFrame into a list of Document objects.\n",
    "    The text_field parameter indicates which column holds the text.\n",
    "    \"\"\"\n",
    "    # Convert each row to a dictionary and use the selected text_field for page_content.\n",
    "    records = df.to_dict(orient=\"records\")\n",
    "    #Documentise the df in BATCHES\n",
    "    docs = []\n",
    "    for idx in tqdm(range(0, len(records), batch_size), desc=\"creating documents\"):\n",
    "        batch_records = records[idx: idx + batch_size]\n",
    "        docs.extend([Document(page_content=rec[text_field], metadata=rec) for rec in batch_records])\n",
    "\n",
    "    return docs\n",
    "\n",
    "    # return [Document(page_content=rec[text_field], metadata=rec) for rec in records]\n",
    "\n",
    "        \n",
    "    # store = LocalFileStore(cache_dir)\n",
    "    # embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    #     embed_model, store, namespace = m_key\n",
    "    # )\n",
    "    # vector_store = FAISS.from_documents(docs, embedder)\n",
    "\n",
    "    # with open(cache_file, 'wb') as f:\n",
    "    #     pickle.dump(vector_store, f)\n",
    "    # print(f'Embeddings saved to cache: {cache_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "if False:\n",
    "    sample_docs = df[:5000]\n",
    "\n",
    "    def time_for_m(m_key, docs):\n",
    "        start_time = time.time()\n",
    "        gen_emb_store(docs, m_key)\n",
    "        end_time = time.time()\n",
    "        return end_time - start_time\n",
    "\n",
    "    num_docs = len(df)\n",
    "    sample_size = len(sample_docs)\n",
    "\n",
    "    for m in models:\n",
    "        time_taken = time_for_m(m, sample_docs)\n",
    "        print(f\"Time taken for {m}: {time_taken} seconds\")\n",
    "        est_time_per_m = (time_taken / sample_size) * num_docs\n",
    "        print(f\"Estimated time for {m} on full dataset: {est_time_per_m} seconds\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "results = compare_models(df, models.keys(), cache_dir='./cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def similarity_search(query, embedding_model, index, k=20):\n",
    "    \"\"\"Perform similarity search using FAISS.\"\"\"\n",
    "    \n",
    "    # Encode query\n",
    "    query_embedding = embedding_model.encode([query], device=device)\n",
    "    \n",
    "    # Ensure correct dtype and shape\n",
    "    query_embedding = np.array(query_embedding, dtype=np.float32).reshape(1, -1)\n",
    "\n",
    "    # Safety checks\n",
    "    if index.ntotal == 0:\n",
    "        raise ValueError(\"FAISS index is empty. Add vectors before querying.\")\n",
    "\n",
    "    if query_embedding.shape[1] != index.d:\n",
    "        raise ValueError(f\"Embedding dimension mismatch: Query({query_embedding.shape[1]}) vs Index({index.d})\")\n",
    "\n",
    "    try:\n",
    "        distances, indices = index.search(query_embedding, k)\n",
    "        return distances, indices\n",
    "    except Exception as e:\n",
    "        print(\"Error in FAISS search:\", e)\n",
    "        return None, None\n",
    "\n",
    "def retrieve_answers(query, index, embedding_model, k=20):\n",
    "    \"\"\"Retrieve top-k similar documents for a query.\"\"\"\n",
    "    distances, indices = similarity_search(query, embedding_model, index, k)\n",
    "\n",
    "    if indices is None:\n",
    "        return []\n",
    "\n",
    "    doc_texts = [df.iloc[i]['review_text'] for i in indices[0] if i >= 0]\n",
    "    return doc_texts\n",
    "\n",
    "# Test similarity search\n",
    "# sample_query = df.iloc[0]['review_text']\n",
    "# sample_index, sample_embedder = results['all-MiniLM-L6-v2']\n",
    "\n",
    "# distances, indices = similarity_search(sample_query, sample_embedder, sample_index)\n",
    "# if distances is not None:\n",
    "#     print(distances, indices)\n",
    "\n",
    "# Test answer query\n",
    "# sample_query = 'What do people like about Spotify?'\n",
    "\n",
    "# for m_key in models.keys():\n",
    "#     answer = retrieve_answers(sample_query, m_key)\n",
    "#     print(f\"Model: {m_key}\")\n",
    "#     print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the quality of documents retrieved and the time it has taken to process, we proceed with the first model: **paraphrase-MiniLM-L6-v2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = \"paraphrase-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index,model = gen_emb_store(df, chosen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the retrevial of chosen_model\n",
    "sample_query = 'What do people like about Spotify?'\n",
    "\n",
    "\n",
    "answer = retrieve_answers(sample_query, index, model,k=100)\n",
    "for i,ans in enumerate(answer):\n",
    "    print(f\"{i+1}: {ans}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding LLM and a building retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.schema import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "def batch_add(docs, embedder, batch_size=512):\n",
    "    batch = docs[0:batch_size]\n",
    "    vector_store = FAISS.from_documents(batch, embedder)\n",
    "    print('one batch added')\n",
    "    for i in tqdm(range(batch_size, len(docs), batch_size), desc=\"Adding batches\"):\n",
    "        batch = docs[i:i + batch_size]\n",
    "        temp = FAISS.from_documents(batch, embedder)\n",
    "        vector_store.merge_from(temp)\n",
    "\n",
    "    return vector_store\n",
    "\n",
    "cache_dir = \"cache\"\n",
    "cache_file = os.path.join(\".\", cache_dir, f\"{chosen_model}-embeddings.pickle\")\n",
    "print(f\"Cache file: {cache_file}\")\n",
    "embed_model = HuggingFaceEmbeddings(model_name=f\"{chosen_model}\", model_kwargs={\"device\": \"cuda\"})\n",
    "\n",
    "if os.path.exists(cache_file):\n",
    "    print(f'Loading embedding from cache: {cache_file}')\n",
    "    with open(cache_file, 'rb') as f:\n",
    "        vector_store = pickle.load(f)\n",
    "        \n",
    "else:\n",
    "    print(f'Generating embeddings for model: {chosen_model}')\n",
    "    store = LocalFileStore(cache_dir)\n",
    "    embedder = CacheBackedEmbeddings.from_bytes_store(embed_model, store, namespace=f\"{chosen_model}\")\n",
    "    print(\"embedder loaded\")\n",
    "    docs = documents_from_df(df)\n",
    "    print(\"generated docs\")\n",
    "    vector_store = batch_add(docs, embedder)\n",
    "\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(vector_store, f)\n",
    "    print(f'Embeddings saved to cache: {cache_file}')\n",
    "\n",
    "# vector_store = results['all-MiniLM-L6-v2'][0]\n",
    "# documents = documents_from_df(df)\n",
    "# doc_dict = {i: doc for i, doc in enumerate(documents)}\n",
    "# doc_store = InMemoryDocstore({i: doc for i, doc in enumerate(documents)})\n",
    "# index_to_docstore_id = {i: i for i in range(len(documents))}\n",
    "pathlib.PosixPath = temp\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# torch.backends.cuda.enable_flash_sdp(True)\n",
    "# torch.backends.cuda.enable_math_sdp(False)\n",
    "# torch.backends.cuda.enable_mem_efficient_sdp(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# llm_model = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "# llm_model = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "llm_model = \"../model\"\n",
    "\n",
    "# hf_token = os.getenv('HUGGINGFACE_HUB_TOKEN') \n",
    "# login(token=hf_token)\n",
    "\n",
    "\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(llm_model)\n",
    "\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "        llm_model,\n",
    "        config=model_config,\n",
    "        quantization_config=bnb_config,\n",
    "        trust_remote_code=True,\n",
    "        device_map='auto',\n",
    "        torch_dtype=torch.float16       # use float16 to reduce memory footprint\n",
    "    )\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    return_full_text=True,\n",
    "    temperature=0.5,\n",
    "    max_new_tokens=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "User question: {question}\n",
    "\n",
    "Answer the user's question using the following context.\n",
    "\n",
    "Follow these rules in order to answer the user's question:\n",
    "1) Your answer should be short (maximum 3 short coherent sentences).\n",
    "2) Use the dataset information on Google Store reviews for Spotify to extract actionable insights.\n",
    "3) Your answer should be a coherent question answering the question with the given context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Your answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template = prompt_template, input_variables=[\"question\", \"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    #verbose=True,\n",
    "    retriever=retriever,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What do people like about Spotify?\"\n",
    "result = qa({\"question\": query, \"chat_history\": []})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def truncate_context(context):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "    max_tokens = 510  # leave space for special tokens and question tokens\n",
    "\n",
    "    tokens = tokenizer.encode(context, add_special_tokens=False)\n",
    "    if len(tokens) > max_tokens:\n",
    "        tokens = tokens[:max_tokens]\n",
    "        context = tokenizer.decode(tokens)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_text_from_query(query, context):\n",
    "\n",
    "    model = transformers.pipeline(\n",
    "        task=\"question-answering\",\n",
    "        model=\"distilbert-base-cased-distilled-squad\",\n",
    "        tokenizer=tokenizer,\n",
    "        # task=\"text-generation\",\n",
    "        return_full_text=True,\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=510\n",
    "    )\n",
    "\n",
    "    context = truncate_context(context)\n",
    "    # Pass both values to the QA pipeline\n",
    "    return model(question=query, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, model = gen_emb_store(df, chosen_model, cache_dir='./cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def answer_query(query):\n",
    "    retrevial_result = retrieve_answers(query, index, model)\n",
    "    context = \" \".join(retrevial_result)\n",
    "    return generate_text_from_query(query, context)\n",
    "\n",
    "# Then run your query\n",
    "print(answer_query(\"What do people like about Spotify?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_query(\"What do users indiate they like about Spotify?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
