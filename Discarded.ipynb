{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sentence_transformers import util\n",
    "\n",
    "# # def similarity_search(query, embedding_model, index, k=10):\n",
    "# #     query_embedding = embedding_model.encode([query], device=device)\n",
    "# #     distances, indices = index.search(query_embedding, k)\n",
    "# #     return distances, indices\n",
    "\n",
    "# def similarity_search(query, embedding_model, index, k=10):\n",
    "#     query_embedding = embedding_model.encode([query], device=device)\n",
    "\n",
    "#     # Ensure correct dtype and shape\n",
    "#     query_embedding = np.array(query_embedding).astype('float32').reshape(1, -1)\n",
    "\n",
    "#     # Debugging prints\n",
    "#     print(\"Query embedding shape:\", query_embedding.shape)\n",
    "#     print(\"Index dimension:\", index.d)\n",
    "#     print(\"Index size:\", index.ntotal)\n",
    "\n",
    "#     distances, indices = index.search(query_embedding, k)\n",
    "#     return distances, indices\n",
    "\n",
    "# def retrieve_answers(query, m_key):\n",
    "#     index, embedding_model = results[m_key]\n",
    "#     distances, indices = similarity_search(query, embedding_model, index)\n",
    "#     doc_texts = [df.iloc[i]['review_text'] for i in indices[0]]\n",
    "#     return doc_texts\n",
    "\n",
    "# #test similarity search\n",
    "# sample_query = df.iloc[0]['review_text']\n",
    "# sample_index, sample_embedder = results['all-MiniLM-L6-v2']\n",
    "# distances, indices = similarity_search(sample_query, sample_embedder, sample_index)\n",
    "# print(distances, indices)\n",
    "\n",
    "# #test answer query\n",
    "# sample_query = 'What do people like about Spotify?'\n",
    "\n",
    "# for m_key in models.keys():\n",
    "#     answer = retrieve_answers(sample_query, m_key)\n",
    "#     print(f\"Model: {m_key}\")\n",
    "#     print(answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_closest(vector_store, embedder, query, k=3):\n",
    "#     q_embed = embedder.embed_query(query)\n",
    "#     return vector_store.similarity_search_by_vector(q_embed, k=k) #, distances=[], labels=[])\n",
    "\n",
    "# query = 'What do people like about Spotify?'\n",
    "\n",
    "# comparisons = {}\n",
    "# for m_key, (vector_store, embedder) in results.items():\n",
    "#     close = get_closest(vector_store, embedder, query)\n",
    "#     comparisons[m_key] = close\n",
    "\n",
    "# for m_key, close in comparisons.items():\n",
    "#     print(f\"Model: {m_key}\")\n",
    "#     for n in close:\n",
    "#         print(n)\n",
    "#     print(\"---------------------------------------- \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import faiss\n",
    "# import torch\n",
    "\n",
    "# # Assume you have an index (e.g. a flat index on CPU)\n",
    "# cpu_index = faiss.IndexFlatL2(128)\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"Using FAISS GPU\")\n",
    "#     # Create GPU resources and transfer the index to GPU 0\n",
    "#     res = faiss.StandardGpuResources()\n",
    "#     gpu_index = faiss.index_cpu_to_gpu(res, 0, cpu_index)\n",
    "#     index = gpu_index\n",
    "# else:\n",
    "#     print(\"Using FAISS CPU\")\n",
    "#     index = cpu_index\n",
    "\n",
    "# # Now use `index` for your similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deduplicating reviews: 100%|██████████| 3004/3004 [00:03<00:00, 828.49it/s] \n"
     ]
    }
   ],
   "source": [
    "# from rapidfuzz import process, fuzz\n",
    "\n",
    "# # Function to remove duplicate reviews while keeping all columns\n",
    "# def deduplicate_dataframe(df, text_column=\"review_text\", threshold=80):\n",
    "#     seen = {}  # Dictionary to track unique reviews with indexes\n",
    "#     unique_indexes = []\n",
    "\n",
    "#     for index, review in tqdm(df[text_column].items(), total=len(df), desc=\"Deduplicating reviews\"):\n",
    "#         # Find best match from seen reviews\n",
    "#         match = process.extractOne(review, seen.keys(), scorer=fuzz.ratio)\n",
    "        \n",
    "#         # If no close match or similarity is below threshold, keep review\n",
    "#         if not match or match[1] < threshold:\n",
    "#             seen[review] = index\n",
    "#             unique_indexes.append(index)\n",
    "\n",
    "#     # Return deduplicated DataFrame\n",
    "#     return df.loc[unique_indexes].reset_index(drop=True)\n",
    "\n",
    "# # Apply deduplication while preserving all columns\n",
    "# df_dedup = deduplicate_dataframe(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (3004, 3)\n",
      "Deduplicated DataFrame shape: (2951, 3)\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Original DataFrame shape: {df.shape}\")\n",
    "# print(f\"Deduplicated DataFrame shape: {df_dedup.shape}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
